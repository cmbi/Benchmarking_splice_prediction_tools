{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import matplotlib.font_manager as font_manager\n",
    "from numpy import nan\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variants that should be analyzed\n",
    "# ABCA4_NCSS, ABCA4_DI or MYBPC3_NCSS\n",
    "variants = 'ABCA4_NCSS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data and store it in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store the scores in a dataframe\n",
    "di = pd.read_excel('variants_scores.xlsx', variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the distribution of variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# variants: ', di.shape[0])\n",
    "print('# non splice altering variants: ', di[di['% Mutant RNA'] <= 20].count()['cDNA variant'])\n",
    "print('# splice altering variants: ', di[di['% Mutant RNA'] > 20].count()['cDNA variant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affects donor/acceptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('donor: ', di[di['affects'] == 'donor'].count()['cDNA variant'])\n",
    "print('acceptor: ', di[di['affects'] == 'acceptor'].count()['cDNA variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for variants that affect the SDS/SAS\n",
    "donor = di['affects'] == \"donor\"\n",
    "acceptor = di['affects'] == \"acceptor\"\n",
    "\n",
    "# Filter for variants that affect splicing or not\n",
    "sa = di['% Mutant RNA'] > 20\n",
    "nsa = di['% Mutant RNA'] <= 20\n",
    "\n",
    "# print the result\n",
    "print('donor + affects splicing: ',di[donor & sa].shape[0])\n",
    "print('donor + does not affect splicing: ',di[donor & nsa].shape[0])\n",
    "print('acceptor + affects splicing: ',di[acceptor & sa].shape[0])\n",
    "print('acceptor + does not affect splicing: ',di[acceptor & nsa].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caclulate distribution around splice site for NCSS variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "column_names = ['RNA','SSFL','MES','NNS','GS', 'splicerover', 'DSSP', 'spliceai','cagi','cadd', 'spidex', 'mmsplice','mtsplice','scap']\n",
    "\n",
    "# only calculate the distribution for NCSS variants\n",
    "if 'NCSS' in variants:\n",
    "    for index in di.index:\n",
    "        \n",
    "        # get the cDNA positions\n",
    "        cdna = di.at[index,'cDNA variant']\n",
    "        \n",
    "        # check if the variant alters splicing\n",
    "        if di.at[index, '% Mutant RNA'] > 20:\n",
    "            sa = 'sa'\n",
    "        else:\n",
    "            sa = ''\n",
    "        \n",
    "        # check if the variant is located upstream or downstream of the splice site\n",
    "        if '-' in cdna:\n",
    "            # check if it is a deletion\n",
    "            if 'del' in cdna:\n",
    "                # depending on the length of the deletion (on or multiple bases) a different handling is required\n",
    "                if '_' in cdna:\n",
    "                    loc = -int((cdna.split('-')[1][:-3]).split('_')[0])\n",
    "                    locations.append((str(loc) + ' ' + sa))\n",
    "                else:\n",
    "                    loc = -int((cdna.split('-')[1][:-3]))\n",
    "                    locations.append((str(loc) + ' ' + sa))\n",
    "            # if the varant is not a deletion, the cdna string can be split to get the location of the variant\n",
    "            else:\n",
    "                loc = -int((cdna.split('-')[1]).split('>')[0][:-1])\n",
    "                locations.append((str(loc) + ' ' + sa))\n",
    "        \n",
    "        # perform the same actions for the downsstream variants but now split the string at + instead of -\n",
    "        elif '+' in cdna:\n",
    "            if 'del' in cdna:\n",
    "                if '_' in cdna:\n",
    "                    loc = int((cdna.split('+')[1][:-3]).split('_')[0])\n",
    "                    locations.append((str(loc) + ' ' + sa))\n",
    "                else:\n",
    "                    loc = int((cdna.split('+')[1][:-3]))\n",
    "                    locations.append((str(loc) + ' ' + sa))\n",
    "            else:\n",
    "                loc = int((cdna.split('+')[1]).split('>')[0][:-1])\n",
    "                locations.append((str(loc) + ' ' + sa))\n",
    "        else:\n",
    "            loc = 0\n",
    "            locations.append((str(loc) + ' ' + sa))\n",
    "\n",
    "# count how often a variant is located at a certain position in the NCSS motif and print the result          \n",
    "Counter(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the missing scores for each tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max value for the tools fror which a delta value has to be calculated\n",
    "delta = dict()\n",
    "delta['SSFL'] = 100\n",
    "delta['MES'] = 12\n",
    "delta['NNS'] = 1\n",
    "delta['GS'] = 15\n",
    "delta['SpliceRover'] = 1\n",
    "delta['DSSP'] = 1\n",
    "\n",
    "# create a dictionary to store the values\n",
    "delta_scores = dict()\n",
    "\n",
    "for index in di.index:\n",
    "        \n",
    "    element = []\n",
    "    \n",
    "    # get the % mutant RNA\n",
    "    value = di.at[index,'% Mutant RNA']\n",
    "    if value > 20:\n",
    "        element.append(1)\n",
    "    else:\n",
    "        element.append(0)\n",
    "    \n",
    "    # calulate the delta scores\n",
    "    for name in delta:\n",
    "        wt = name + '_wt'\n",
    "        var = name + '_var'\n",
    "        if di.at[index,wt] == 0:\n",
    "            score = float(di.at[index,var])/delta[name]\n",
    "        else: \n",
    "            score = (float(di.at[index,var])-float(di.at[index,wt]))/float(di.at[index,wt])\n",
    "        element.append(np.absolute(score))\n",
    "    \n",
    "    # add the value of the SpliceAI score \n",
    "    element.append(di.at[index,'SpliceAI'])\n",
    "    \n",
    "    # add the absolute value of the Cagi score \n",
    "    element.append(np.absolute(di.at[index,'CAGI']))\n",
    "    \n",
    "    # add the absolute value of the CADD score \n",
    "    element.append(np.absolute(di.at[index,'CADD']))\n",
    "    \n",
    "    # add the absolute value of the Spidex score\n",
    "    element.append(np.absolute(di.at[index,'Spidex']))\n",
    "    \n",
    "    # add the absolute value of the MMsplice score \n",
    "    element.append(np.absolute(di.at[index,'MMSplice']))\n",
    "    \n",
    "    # add the absolute value of the MMsplice score\n",
    "    element.append(np.absolute(di.at[index,'MTSplice']))\n",
    "    \n",
    "    # add the CAGI score\n",
    "    element.append(np.absolute(di.at[index,'SCAP']))\n",
    "        \n",
    "    delta_scores[index] = element\n",
    "\n",
    "delta_df = pd.DataFrame(delta_scores)\n",
    "delta_df = delta_df.transpose()\n",
    "delta_df.columns = column_names\n",
    "\n",
    "delta_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with 0\n",
    "delta_df = delta_df.replace(nan, 0)\n",
    "\n",
    "# set the threshold for the values that are considered to affect splicing.\n",
    "# Everything above the threshold is defined to affect splicing\n",
    "threshold = []\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.SSFL)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.MES)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.NNS)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.GS)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.splicerover)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.DSSP)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.spliceai)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.cagi)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.cadd)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.spidex)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.mmsplice)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.mtsplice)[0])\n",
    "threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df.scap)[0])\n",
    "\n",
    "print(threshold)\n",
    "\n",
    "# create a new dataframe to store the classification \n",
    "classification = pd.DataFrame(delta_df['RNA']) \n",
    "\n",
    "# add the classification of the different tools to the dataframe\n",
    "classification['SSFL'] = (delta_df.SSFL > threshold[0]).astype('int')\n",
    "classification['MES'] = (delta_df.MES > threshold[1]).astype('int')\n",
    "classification['NNS'] = (delta_df.NNS > threshold[2]).astype('int')\n",
    "classification['GS'] = (delta_df.GS > threshold[3]).astype('int')\n",
    "classification['splicerover'] = (delta_df.splicerover > threshold[4]).astype('int')\n",
    "classification['DSSP'] = (delta_df.DSSP > threshold[5]).astype('int')\n",
    "classification['spliceai'] = (delta_df.spliceai > threshold[6]).astype('int')\n",
    "classification['cagi'] = (delta_df.cagi > threshold[7]).astype('int')\n",
    "classification['cadd'] = (delta_df.cadd > threshold[8]).astype('int')\n",
    "classification['spidex'] = (delta_df.spidex > threshold[9]).astype('int')\n",
    "classification['mmsplice'] = (delta_df.mmsplice > threshold[10]).astype('int')\n",
    "classification['mtsplice'] = (delta_df.mtsplice > threshold[11]).astype('int')\n",
    "classification['scap'] = (delta_df.scap > threshold[12]).astype('int')\n",
    "\n",
    "classification['consensus'] = ((classification['SSFL'] + classification['MES'] + classification['NNS'] + classification['GS']) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculcate the confusion matrix \n",
    "# the confusion matrix is in the format [[TN FP][FN TP]]\n",
    "for name in column_names[1:]:\n",
    "    print(name)\n",
    "    print(confusion_matrix(classification.RNA.values, classification[name].values))\n",
    "\n",
    "print('consensus')\n",
    "print(confusion_matrix(classification.RNA.values, classification['consensus'].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

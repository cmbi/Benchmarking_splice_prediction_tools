{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import matplotlib.font_manager as font_manager\n",
    "from numpy import nan\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from functions import read_scores_from_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variants that should be analyzed\n",
    "# ABCA4_NCSS, ABCA4_DI or MYBPC3_NCSS\n",
    "variants = 'ABCA4_NCSS'\n",
    "\n",
    "column_names = ['RNA','CADD','DSSP','GeneSplicer', 'MaxEntScan', 'MMSplice', 'MTSplice', 'NNSPLICE', 'S-CAP', 'SPIDEX', 'SpliceAI', 'SpliceRover', 'SpliceSiteFinder-like']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data and store it in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store the scores in a dataframe\n",
    "di = pd.read_excel('variants_scores.xlsx', variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the distribution of variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# variants: ', di.shape[0])\n",
    "print('# non splice altering variants: ', di[di['% Mutant RNA'] <= 20].count()['cDNA variant'])\n",
    "print('# splice altering variants: ', di[di['% Mutant RNA'] > 20].count()['cDNA variant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affects donor/acceptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('donor: ', di[di['affects'] == 'donor'].count()['cDNA variant'])\n",
    "print('acceptor: ', di[di['affects'] == 'acceptor'].count()['cDNA variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for variants that affect the SDS/SAS\n",
    "donor = di['affects'] == \"donor\"\n",
    "acceptor = di['affects'] == \"acceptor\"\n",
    "\n",
    "# Filter for variants that affect splicing or not\n",
    "sa = di['% Mutant RNA'] > 20\n",
    "nsa = di['% Mutant RNA'] <= 20\n",
    "\n",
    "# print the result\n",
    "print('donor + affects splicing: ',di[donor & sa].shape[0])\n",
    "print('donor + does not affect splicing: ',di[donor & nsa].shape[0])\n",
    "print('acceptor + affects splicing: ',di[acceptor & sa].shape[0])\n",
    "print('acceptor + does not affect splicing: ',di[acceptor & nsa].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caclulate distribution around splice site for NCSS variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "\n",
    "# only calculate the distribution for NCSS variants\n",
    "if 'NCSS' in variants:\n",
    "    for index in di.index:\n",
    "        \n",
    "        # get the ss positions\n",
    "        pos = di.at[index,'position ss']\n",
    "        \n",
    "        # check if the variant alters splicing\n",
    "        if di.at[index, '% Mutant RNA'] > 20:\n",
    "            sa = 'sa'\n",
    "        else:\n",
    "            sa = ''\n",
    "            \n",
    "        # check if the variant affects the donor or acceptor\n",
    "        affects = di.at[index,'affects']\n",
    "\n",
    "        locations.append((str(pos) + ' ' + sa + ' ' + affects))\n",
    "\n",
    "# count how often a variant is located at a certain position in the NCSS motif and print the result          \n",
    "Counter(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the missing scores for each tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df = read_scores_from_excel('variants_scores.xlsx', variants, fillna = False, diall = True)\n",
    "delta_df.columns = column_names\n",
    "\n",
    "delta_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    @target : Matrix with dependent or target data, where rows are observations\n",
    "    @predicted : Matrix with predicted data, where rows are observations\n",
    "    Returns list type, with optimal cutoff value\n",
    "    \n",
    "    adapted from: https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with 0\n",
    "delta_df = delta_df.replace(nan, 0)\n",
    "\n",
    "# set the threshold for the values that are considered to affect splicing.\n",
    "# Everything above the threshold is defined to affect splicing\n",
    "threshold = []\n",
    "for name in column_names[1:]:\n",
    "    threshold.append(Find_Optimal_Cutoff(delta_df['RNA'], delta_df[name])[0])\n",
    "\n",
    "print(threshold)\n",
    "\n",
    "# create a new dataframe to store the classification \n",
    "classification = pd.DataFrame(delta_df['RNA']) \n",
    "\n",
    "# add the classification of the different tools to the dataframe\n",
    "i = 0\n",
    "for name in column_names[1:]:\n",
    "    classification[name] = (delta_df[name] > threshold[i]).astype('int')\n",
    "    i += 1\n",
    "\n",
    "\n",
    "classification['consensus'] = ((classification['SpliceSiteFinder-like'] + classification['MaxEntScan'] + classification['NNSPLICE'] + classification['GeneSplicer']) > 1)\n",
    "\n",
    "# calculcate the confusion matrix \n",
    "# the confusion matrix is in the format [[TN FP][FN TP]]\n",
    "for name in column_names[1:]:\n",
    "    print(name)\n",
    "    print(confusion_matrix(classification.RNA.values, classification[name].values))\n",
    "\n",
    "print('consensus')\n",
    "print(confusion_matrix(classification.RNA.values, classification['consensus'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
